{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video_cap= cv2.VideoCapture(0) #accesing main camera\n",
    "#while True: #initiating infinite loop, camera hmesha on rhega\n",
    "#    ret, video_data= video_cap.read()\n",
    "#    cv2.imshow('video_live', video_data)\n",
    "#    if cv2.waitKey(10)==ord(\"a\"):\n",
    "#        break\n",
    "#video_cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 69\u001b[0m\n\u001b[0;32m     66\u001b[0m     face_roi \u001b[38;5;241m=\u001b[39m gray[y:y\u001b[38;5;241m+\u001b[39mh, x:x\u001b[38;5;241m+\u001b[39mw]\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# Perform facial authentication with the extracted face region\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     \u001b[43mmatch_images\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC:/Users/Piyush/Desktop/ML projects/Face-Detection/data/negative/Aaron_Peirsol_0001\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mface_roi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Display the resulting frame\u001b[39;00m\n\u001b[0;32m     72\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFacial Authentication\u001b[39m\u001b[38;5;124m'\u001b[39m, video_data)\n",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m, in \u001b[0;36mmatch_images\u001b[1;34m(ref_img_path, live_img_gray)\u001b[0m\n\u001b[0;32m     26\u001b[0m matches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(matches, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x\u001b[38;5;241m.\u001b[39mdistance)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Draw first 10 matches\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m matched_img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrawMatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref_img\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_kp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlive_img_gray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlive_kp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatches\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Display the matched image\u001b[39;00m\n\u001b[0;32m     32\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMatched Image\u001b[39m\u001b[38;5;124m'\u001b[39m, matched_img)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "face_cap= cv2.CascadeClassifier(\"C:/Users/Piyush/.conda/envs/py120/Lib/site-packages/cv2/data/haarcascade_frontalface_default.xml\")\n",
    "video_cap= cv2.VideoCapture(0) #accesing main camera\n",
    "\n",
    "\n",
    "#function to authenticaate images!!\n",
    "\n",
    "# Define the match_images function\n",
    "def match_images(ref_img_path, live_img_gray):\n",
    "    # Loading the reference image\n",
    "    ref_img = cv2.imread(ref_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "    # Initialize the ORB detector\n",
    "    orb = cv2.ORB_create()\n",
    "\n",
    "    # Find the keypoints and descriptors with ORB\n",
    "    ref_kp, ref_des = orb.detectAndCompute(ref_img, None)\n",
    "    live_kp, live_des = orb.detectAndCompute(live_img_gray, None)\n",
    "\n",
    "    # Initialize the Brute-Force Matcher\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "    # Match descriptors\n",
    "    matches = bf.match(ref_des, live_des)\n",
    "\n",
    "    # Sort matches by their distance\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    # Draw first 10 matches\n",
    "    matched_img = cv2.drawMatches(ref_img, ref_kp, live_img_gray, live_kp, matches[:10], None, flags=2)\n",
    "\n",
    "    # Display the matched image\n",
    "    cv2.imshow('Matched Image', matched_img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Perform further processing to determine if the live image matches the reference image\n",
    "    # You can implement additional logic here based on your requirements\n",
    "\n",
    "# Start video capture from the default webcam\n",
    "video_cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize the face cascade classifier\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Start video capture from the default webcam\n",
    "video_cap = cv2.VideoCapture(0)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video capture\n",
    "    ret, video_data = video_cap.read()\n",
    "\n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(video_data, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces in the grayscale frame\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw a rectangle around the detected face\n",
    "        cv2.rectangle(video_data, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        # Extract the detected face region\n",
    "        face_roi = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # Perform facial authentication with the extracted face region\n",
    "        match_images(\"C:/Users/Piyush/Desktop/ML projects/Face-Detection/data/negative/Aaron_Peirsol_0001\", face_roi)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Facial Authentication', video_data)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the video capture\n",
    "video_cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py120",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
